import os
import requests
from bs4 import BeautifulSoup
import time


def download_images(url, save_folder, max_images=50):
    """
    Verilen URL'den resimleri akÄ±llÄ±ca bulur ve indirir.
    Birden fazla CSS seÃ§iciyi (selector) sÄ±rasÄ±yla dener.
    """
    # 1. KlasÃ¶r yoksa oluÅŸtur
    if not os.path.exists(save_folder):
        os.makedirs(save_folder)
        print(f"ğŸ“ KlasÃ¶r oluÅŸturuldu: {save_folder}")

    # 2. Bot gibi gÃ¶rÃ¼nmemek iÃ§in User-Agent
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    print(f"ğŸŒ BaÄŸlanÄ±lÄ±yor: {url}")

    try:
        response = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(response.content, 'lxml')

        # --- AKILLI SEÃ‡Ä°CÄ° KISMI ---
        # LCW'nin olasÄ± resim sÄ±nÄ±flarÄ±nÄ± sÄ±rasÄ±yla deniyoruz
        possible_selectors = [
            "img.product-image",  # En yaygÄ±n olan
            "img.product-item__image",  # Yeni tasarÄ±m ihtimali
            ".product-card img",  # Genel kapsayÄ±cÄ±
            "img.lazy"  # Bazen lazy load kullanÄ±lÄ±r
        ]

        img_tags = []
        used_selector = ""

        for selector in possible_selectors:
            found_tags = soup.select(selector)
            if len(found_tags) > 0:
                img_tags = found_tags
                used_selector = selector
                print(f"âœ… '{selector}' ile {len(img_tags)} adet resim yakalandÄ±.")
                break

        if len(img_tags) == 0:
            print("âš ï¸ HÄ°Ã‡ RESÄ°M BULUNAMADI! Site yapÄ±sÄ± farklÄ± olabilir.")
            print("Ä°pucu: SayfayÄ± tarayÄ±cÄ±da aÃ§Ä±p F12 ile resim kodunu kontrol et.")
            return

        # --- Ä°NDÄ°RME DÃ–NGÃœSÃœ ---
        count = 0
        for i, img in enumerate(img_tags):
            if count >= max_images:
                break

            # Resim linkini yakala (farklÄ± etiket ihtimalleri)
            img_url = img.get('data-src') or img.get('src') or img.get('data-original')

            # Link dÃ¼zeltme (Ã¶rn: //image.jpg -> https://image.jpg)
            if img_url and img_url.startswith("//"):
                img_url = "https:" + img_url

            # Sadece geÃ§erli resim linklerini al
            if img_url and "http" in img_url and (".jpg" in img_url or ".jpeg" in img_url or ".webp" in img_url):
                try:
                    img_data = requests.get(img_url, headers=headers, timeout=5).content

                    # Dosya isimlendirme
                    prefix = os.path.basename(save_folder)
                    filename = os.path.join(save_folder, f"{prefix}_{count}.jpg")

                    with open(filename, 'wb') as handler:
                        handler.write(img_data)

                    # Konsolu Ã§ok doldurmamak iÃ§in her 10 resimde bir bilgi verelim
                    if count % 10 == 0:
                        print(f"   â¬‡ï¸ {count + 1}. resim indirildi...")

                    count += 1
                    time.sleep(0.1)

                except Exception as e:
                    pass  # HatalÄ± resmi atla, devam et

        print(f"ğŸ TAMAMLANDI! {save_folder} klasÃ¶rÃ¼ne toplam {count} resim indi.\n")

    except Exception as e:
        print(f"â›” Kritik Hata: {e}")


# --- AYARLAR VE Ã‡ALIÅTIRMA ---

if __name__ == "__main__":
    # SENÄ°N VERDÄ°ÄÄ°N LÄ°NKLER

    # 1. PopÃ¼ler (Ã‡ok Satanlar)
    popular_link = "https://www.lcw.com/mvc/populer-erkek-urunleri?urun-tipi=tisort"

    # 2. PopÃ¼ler Olmayan (Ä°ndirim OranÄ± YÃ¼ksek / Stok Eritme)
    unpopular_link = "https://www.lcw.com/erkek-tisort-t-345?siralama=indirim-orani"

    print("--- SCRAPING BAÅLIYOR ---\n")

    # PopÃ¼ler verileri indir
    download_images(popular_link, "dataset/popular", max_images=100)

    # Normal verileri indir
    download_images(unpopular_link, "dataset/unpopular", max_images=100)